{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "np.random.seed(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "n = 20\n",
    "m = 100\n",
    "\n",
    "# random input and output data (random, normal)\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Random and IID generation of x (Changes results of Newton method)\n",
    "# x = np.random.uniform(size=n).reshape(n,1)\n",
    "x = np.random.randn(n,1)\n",
    "\n",
    "# IID generation of A\n",
    "A = np.random.uniform(size=n)\n",
    "for i in range(m-1):\n",
    "    A = np.column_stack((A,np.random.uniform(size=n)))\n",
    "\n",
    "# Computing y\n",
    "y = np.square(A.T@x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss @epoch (999) = 2.9560550579298493e-05\n",
      "Loss @epoch (1999) = 5.5104617905385015e-14\n",
      "Loss @epoch (2999) = 1.0253424870338469e-22\n",
      "Loss @epoch (3999) = 2.884648159610015e-26\n",
      "Loss @epoch (4999) = 2.884648159610015e-26\n"
     ]
    }
   ],
   "source": [
    "# Newton's method \n",
    "# Able to reach global minima always in IID generation of x\n",
    "# Sometimes reaches global minima, while other time trapped in saddle point, when x generated randomly\n",
    "epochs = 5000\n",
    "\n",
    "# Random and IID generation of x (Changes results of Newton method)\n",
    "# x_1 = np.random.uniform(size=n).reshape(n,1) # (always reaches glocal minima here)\n",
    "x_1 = np.random.randn(n,1) # Run it again to reach global minima (as only sometimes reaches)\n",
    "\n",
    "for t in range(epochs):\n",
    "    \n",
    "    diff = y - np.square(A.T@x_1)\n",
    "    loss = 0.25*(np.linalg.norm(diff)**2)\n",
    "    \n",
    "    if t % 1000 == 999:\n",
    "        print('Loss @epoch ({0}) = {1}'.format(t, loss))\n",
    "        \n",
    "    # Gradient calculation\n",
    "    grad_x = -A@np.multiply(A.T@x_1,y - np.square(A.T@x_1))\n",
    "    \n",
    "    # Hessian calculation\n",
    "    K = y - 3*np.square(A.T@x_1)\n",
    "    L = A@np.diag(K[:,0])\n",
    "    hess_x = -L@A.T\n",
    "    \n",
    "    # Parameter updation\n",
    "    x_1 -= learning_rate*np.linalg.inv(hess_x)@ grad_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss @epoch (0) = 1360.8425277976096\n",
      "Loss @epoch (1) = 181.78711029444412\n",
      "Loss @epoch (2) = 84.25631382897485\n",
      "Loss @epoch (3) = 47.32465194270611\n",
      "Loss @epoch (4) = 7.201327708459321\n",
      "Loss @epoch (5) = 0.1671503358185912\n",
      "Loss @epoch (6) = 7.513014317964778e-05\n",
      "Loss @epoch (7) = 2.2009186792549134e-11\n",
      "Loss @epoch (8) = 2.032729408615824e-24\n",
      "Loss @epoch (9) = 1.032141169749262e-26\n"
     ]
    }
   ],
   "source": [
    "# Gauss Newton (approximation of Newton's method)\n",
    "epochs = 10\n",
    "\n",
    "# Able to reach global minima (In both type of generation of x)\n",
    "# x_2 = np.random.uniform(size=n).reshape(n,1)\n",
    "x_2 = np.random.randn(n,1)\n",
    "\n",
    "for t in range(epochs):\n",
    "    \n",
    "    diff = y - np.square(A.T@x_2)\n",
    "    loss = 0.25*(np.linalg.norm(diff)**2)\n",
    "    \n",
    "    print('Loss @epoch ({0}) = {1}'.format(t, loss))\n",
    "        \n",
    "    # Jacobian calculation\n",
    "    K = A.T@x_2\n",
    "    Dr_x = -(A@np.diag(K[:,0])).T\n",
    "    \n",
    "    # Intermediates calculation\n",
    "    r_k = 0.5*(y - np.square(A.T@x_2))\n",
    "    A_k = Dr_x\n",
    "    b_k = Dr_x@x_2 - r_k\n",
    "    \n",
    "    # Parameter updation\n",
    "    x_2 = np.linalg.inv(A_k.T@A_k)@(A_k.T@b_k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
